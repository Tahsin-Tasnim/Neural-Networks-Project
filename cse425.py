# -*- coding: utf-8 -*-
"""CSE425.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KJtMAWNoEpJ6oesEFLxVbIeDhoW4rCjL
"""

!pip install torch torchvision datasets scikit-learn matplotlib seaborn --upgrade

from datasets import load_dataset

# This will download and cache the MNIST dataset from the Hugging Face hub
mnist = load_dataset("ylecun/mnist")

import torch
from torchvision import transforms

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

def preprocess(example):
    image = transform(example["image"])
    return {"image": image.view(-1)}

mnist = mnist.map(preprocess)

import torch.nn as nn

class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(784, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 32)
        )
        self.decoder = nn.Sequential(
            nn.Linear(32, 64),
            nn.ReLU(),
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, 784),
            nn.Tanh()
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return encoded, decoded

from torch.utils.data import DataLoader, TensorDataset
import torch
import torch.nn as nn
from torchvision import transforms

# Convert PIL images to tensor and flatten
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Lambda(lambda x: x.view(-1))  # Flatten 28x28 -> 784
])

train_data = torch.stack([transform(example['image']) for example in mnist['train']])
dataset = TensorDataset(train_data)
dataloader = DataLoader(dataset, batch_size=128, shuffle=True)

# Define your Autoencoder model
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(784, 128),
            nn.ReLU(),
            nn.Linear(128, 64)
        )
        self.decoder = nn.Sequential(
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, 784),
            nn.Sigmoid()
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return encoded, decoded

# Training setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = Autoencoder().to(device)
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

# Training loop
for epoch in range(10):
    for batch in dataloader:
        imgs = batch[0].to(device)
        encoded, decoded = model(imgs)
        loss = criterion(decoded, imgs)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")

model.eval()
with torch.no_grad():
    embeddings = model.encoder(train_data.to(device)).cpu()

from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=10, random_state=42)
cluster_labels = kmeans.fit_predict(embeddings)

from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

tsne = TSNE(n_components=2, random_state=42)
tsne_results = tsne.fit_transform(embeddings)

plt.figure(figsize=(8, 6))
plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=cluster_labels, cmap='tab10', s=5)
plt.title("t-SNE visualization of clustered embeddings")
plt.colorbar()
plt.show()

from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score

silhouette = silhouette_score(embeddings, cluster_labels)
db_index = davies_bouldin_score(embeddings, cluster_labels)
ch_index = calinski_harabasz_score(embeddings, cluster_labels)

print(f"Silhouette Score: {silhouette:.4f}")
print(f"Davies-Bouldin Index: {db_index:.4f}")
print(f"Calinski-Harabasz Index: {ch_index:.4f}")



